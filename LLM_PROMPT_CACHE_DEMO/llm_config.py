"""
LLM æä¾›å•†é…ç½®æ¨¡å—

ä½¿ç”¨æ–¹æ³•ï¼š
åœ¨ä½ çš„ä»£ç ä¸­ä¿®æ”¹ LLM_CHOICE çš„å€¼æ¥åˆ‡æ¢ä¸åŒçš„ LLMï¼š
  1 = DeepSeek
  2 = OpenAI (GPT)
  3 = ç¡…åŸºæµåŠ¨ (SiliconFlow)
"""

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================
# ğŸ”§ åœ¨è¿™é‡Œä¿®æ”¹æ•°å­—æ¥åˆ‡æ¢ LLM
# ============================================
#   1 = DeepSeekï¼ˆé»˜è®¤ï¼‰
#   2 = OpenAI (GPT)
#   3 = ç¡…åŸºæµåŠ¨ (SiliconFlow)
#   4 = Custom Cloud (Claude/Other)
# ============================================
LLM_CHOICE = 1


# LLM é…ç½®å­—å…¸
LLM_CONFIGS = {
    1: {
        "name": "DeepSeek",
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
        "base_url": os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com"),
        "model": "deepseek-chat"
    },
    2: {
        "name": "OpenAI",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "base_url": os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
        "model": "gpt-5"  # æˆ– gpt-4o, gpt-3.5-turbo
    },
    3: {
        "name": "ç¡…åŸºæµåŠ¨",
        "api_key": os.getenv("SILICONFLOW_API_KEY"),
        "base_url": os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1"),
        "model": "deepseek-ai/DeepSeek-V3"  # ç¡…åŸºæµåŠ¨çš„æ¨¡å‹å
    },
    4: {
        "name": "Custom Cloud (Claude/Other)",
        "api_key": os.getenv("CUSTOM_API_KEY"),
        "base_url": os.getenv("CUSTOM_BASE_URL", "https://api.example.com/v1"),
        "model": os.getenv("CUSTOM_MODEL_NAME", "claude-3-5-sonnet-20240620") # é»˜è®¤ä½¿ç”¨ Claude 3.5 Sonnetï¼Œå¯é€šè¿‡ .env ä¿®æ”¹
    }
}


def get_llm_config():
    """è·å–å½“å‰é€‰æ‹©çš„ LLM é…ç½®"""
    config = LLM_CONFIGS.get(LLM_CHOICE)
    if not config:
        raise ValueError(f"æ— æ•ˆçš„ LLM_CHOICE: {LLM_CHOICE}ï¼Œè¯·è®¾ç½®ä¸º 1/2/3")
    
    if not config["api_key"]:
        raise ValueError(f"è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® {config['name']} çš„ API Key")
    
    print(f"ğŸ“¡ å½“å‰ä½¿ç”¨: {config['name']} ({config['model']})")
    return config


# å¯¼å‡ºé…ç½®
config = get_llm_config()
API_KEY = config["api_key"]
BASE_URL = config["base_url"]
MODEL_NAME = config["model"]

from openai import OpenAI
def get_client():
    return OpenAI(api_key=API_KEY, base_url=BASE_URL)

def get_model_name():
    return MODEL_NAME
